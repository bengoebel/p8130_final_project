---
title: "p8130_final_project_BG_JA"
author: "Benjamin Goebel, Jesse Ames"
date: "12/14/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(stringr)
library(patchwork)
```

Let's define helpful functions.
```{r}
# Functions

# Purpose: Calculates the Pearson's correlation coefficient between every
# variable in the data set and a specified variable.
# Arguments: v_name: a variable of type character that is the variable name
# Returns: A knitted table of correlations.
get_cor_by_var <- function(v_name) {
  cdi_slim %>%
  map(~cor(as.numeric(.x), pull(cdi, v_name), method = "pearson")) %>%
  as_tibble() %>%
  pivot_longer(CRM_1000:log_pop_density,
               names_to = "variables",
               values_to = "r") %>%
  mutate(
    sign = ifelse(r < 0, "-", "+"),
    r = abs(r)
  ) %>%
  arrange(desc(r)) %>%
  knitr::kable()
}

# Purpose: Fits the model and gets the model adjusted r-squared.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: A numeric, the model adjusted r-squared.
get_mod_adj_r_squared <- function(mod, data = cdi) {
  lm(mod, data = data) %>%
  broom::glance() %>%
  pull(adj.r.squared)
}

# Purpose: Performs cross validation on a model specified by its formula.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: A column vector of the model root mean squared errors generated by the validation procedure.
get_cv_rmse <- function(mod, data = cdi) {
  set.seed(1)
  crossv_mc(data, 1000) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  ) %>%
  mutate(
    fitted_mod = map(train, ~lm(mod, data = .x))
  ) %>%
  mutate(
    rmse_mod = map2_dbl(fitted_mod, test, ~rmse(model = .x, data = .y))
  ) %>%
  pull(rmse_mod)
}

# Purpose: Fits model.
#          Plots model residual as a function of model prediction for the given
#          model formula.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: The ggplot.
plot_model_residuals <- function(mod, data = cdi) {
  fitted_mod <- lm(mod, data = data) 
  cdi %>%
  add_predictions(fitted_mod) %>%
  add_residuals(fitted_mod) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  theme_bw() +
  labs(
    title = ""
  ) +
  theme(plot.title = element_text(hjust = 0.5))
}

# Purpose: Fits the specified model and creates a QQ Plot.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: The plot.
plot_mod_qq <- function(mod, data = cdi) {
  mod %>%
  lm(data = data) %>%
  plot(which = 2)
}


# Purpose: Fits the specified model and creates a leverage plot.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: The plot.
plot_mod_leverage <- function(mod, data = cdi) {
  mod %>%
  lm(data = data) %>%
  plot(which = 5)
}
```

Let's begin by reading in the data and adding a column for the crime rate
per 1,000 people in the county population. We will name this column `CRM_1000`.
We will then recode the region variable as a factor.
```{r message=FALSE}
cdi <- read_csv(here::here("data", "cdi.csv")) %>%
  mutate(CRM_1000 = (crimes/pop) * 1000,
         state = as.factor(state),
         region = as.factor(region),
         region = fct_recode(region, "Northeast" = "1", "North Central" = "2",
                             "South" = "3", "West" = "4"),
         pop_density = pop/area,
         log_pop18 = log(pop18),
         log_pop65 = log(pop65),
         log_hsgrad = log(hsgrad),
         log_bagrad = log(bagrad),
         log_poverty = log(poverty),
         log_unemp = log(unemp),
         log_totalinc = log(totalinc),
         log_pcincome = log(pcincome),
         log_pop_density = log(pop_density)
         ) %>% 
  dplyr::select(-id, -state, -cty, -docs, -beds, -crimes, -pop, -area) %>% 
  dplyr::select(CRM_1000, region, everything())
```

```{r, message=F, echo=F}
cdi_long = 
  cdi %>% 
    pivot_longer(
      pop18:log_pop_density,
      names_to = "var",
      values_to = "val"
    ) %>% 
  mutate(
    trans = case_when(grepl('log_', var) ~ 'log',
                     TRUE ~ 'ori'
    ),
    trans = factor(trans, levels = c("ori", "log"), labels =c("Untransformed", "log Transformed")),
    var = str_replace(var, "log_", ""),
    var = factor(var, levels = c("pop18", "pop65", "hsgrad", "bagrad", "poverty", "unemp", "pcincome", "totalinc", "pop_density"))
  )

dens_plot_gen = function(v, b){
  
  if(!b){
    cdi_long %>% 
      filter(var == v) %>% 
      ggplot(aes(x = val)) +
      geom_boxplot() +
      theme_minimal() +
      theme(
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.text.x=element_blank()
      ) +
      facet_grid(var ~ trans, switch = "y", scales = "free") +
      theme(
        strip.text.y.left = element_text(angle = 0),
        strip.text.x = element_blank()
      )
  }else{
    cdi_long %>% 
      filter(var == v) %>% 
      ggplot(aes(x = val)) +
      geom_boxplot() +
      theme_minimal() +
      theme(
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.text.x=element_blank()
      ) +
      facet_grid(var ~ trans, switch = "y", scales = "free") +
      theme(
        strip.text.y.left = element_text(angle = 0)
      )
  }
}

var_list = c("pop18", "pop65", "hsgrad", "bagrad", "poverty", "unemp", "pcincome", "totalinc", "pop_density")

plot_1 = dens_plot_gen(var_list[1], T)
plot_2 = dens_plot_gen(var_list[2], F)
plot_3 = dens_plot_gen(var_list[3], F)
plot_4 = dens_plot_gen(var_list[4], F)
plot_5 = dens_plot_gen(var_list[5], F)
plot_6 = dens_plot_gen(var_list[6], F)
plot_7 = dens_plot_gen(var_list[7], F)
plot_8 = dens_plot_gen(var_list[8], F)
plot_9 = dens_plot_gen(var_list[9], F)

patch_1 = plot_1 / plot_2 / plot_3 / plot_4 / plot_5 / plot_6 / plot_7 / plot_8 / plot_9

patch_1 + 
  plot_annotation(title = 'Untransformed and log Transformed Variable Distributions in the CDI Dataset',
                  theme = theme(plot.title = element_text(size = 14)))
```

Based on this boxplot, we decided to log transform all continuous variables
except high school graduation. We can remove all unused variables now.

```{r}
cdi_slim <-  
  cdi %>% 
  select(-c(pop18, pop65, bagrad, poverty, unemp, pcincome, totalinc, 
            pop_density, log_hsgrad))
```


Now, let's calculate the Pearson's correlation coefficient between every variable
in the data set and `CRM_1000`.

```{r warning=FALSE}
get_cor_by_var("CRM_1000")
```

Here, we perform stepwise selection based on AIC.

```{r}
# keep only the predictors needed to build the model using pcincome as income measure
pcincome_model = 
  cdi %>% 
  dplyr::select(-c(pop18, pop65, bagrad, poverty, unemp, pcincome, totalinc, log_totalinc, pop_density, log_hsgrad))

# get first full mlr
fit_1 = lm(CRM_1000 ~ ., data = pcincome_model)
## summary(fit_1) # aRs = 0.5309
## boxcox(fit_1) # we ignore the square root tranformation for a more sensible interpretation

# run stepwise and get a list of highly effective predictors
step(fit_1, direction = 'both')
fit_2 = lm(CRM_1000 ~ region + log_pop18 + log_poverty + log_pcincome + log_pop_density, data = pcincome_model)
## summary(fit_2) # aRs = 0.5355; improved with 8 significant coefs
## plot(fit_2) # rows 6, 215, 371 seem to contain outliers; treat them as influential observations...

# check collinearity and found low correlation
## check_collinearity(fit_2)

fit_3 = lm(CRM_1000 ~ (region + log_pop18 + log_poverty + log_pcincome + log_pop_density)*(region + log_pop18 + log_poverty + log_pcincome + log_pop_density), data = pcincome_model) 
## summary(fit_3) # aRs = 0.5748; improved, but each predictor doesn't seem as significant
fit_4 = lm(CRM_1000 ~ (region + log_pop18 + log_poverty + log_pcincome + log_pop_density)*region, data = pcincome_model) 
## summary(fit_4) # aRs = 0.5437, 6 significant coefs
fit_5 = lm(CRM_1000 ~ (region + log_pop18 + log_poverty + log_pcincome + log_pop_density)*log_pop18, data = pcincome_model) 
## summary(fit_5) # aRs = 0.5358, 2 significant coefs
fit_6 = lm(CRM_1000 ~ (region + log_pop18 + log_poverty + log_pcincome + log_pop_density)*log_poverty, data = pcincome_model) 
## summary(fit_6) # aRs = 0.562, 6 significant coefs
fit_7 = lm(CRM_1000 ~ (region + log_pop18 + log_poverty + log_pcincome + log_pop_density)*log_pcincome, data = pcincome_model) 
## summary(fit_7) # aRs = 0.5553, 4 significant coefs
fit_8 = lm(CRM_1000 ~ (region + log_pop18 + log_poverty + log_pcincome + log_pop_density)*log_pop_density, data = pcincome_model) 
## summary(fit_8) # aRs = 0.5717, 8 significant coefs
```

Here, we perform backward elimination based on BIC.
```{r}
totalincome_model_df = 
  cdi %>% 
  dplyr::select(-c(pop18, pop65, bagrad, poverty, unemp, pcincome, totalinc, log_pcincome, pop_density, log_hsgrad))
lin_transform <- lm(CRM_1000 ~., data = totalincome_model_df)
bic_model5 <- step(lin_transform, direction = "backward", trace = FALSE,
                   k = log(nobs(lin_transform)))
summary(bic_model5)
```


Now, let's define our candidate models.
```{r}
# Define model formulas and put in a list
model_A <- "CRM_1000 ~ region + log_pop_density + log_totalinc + log_bagrad + log_poverty"
model_B <- "CRM_1000 ~ region + log_pop_density + log_totalinc + log_poverty"
model_C <- "CRM_1000 ~ region + log_pop_density + log_pcincome + log_poverty"


model_list <-  
  list(
    model_A = model_A,
    model_B = model_B,
    model_C = model_C
  )
```

Here is each model's adjusted R-squared value.
```{r}
# Get each model's adjusted r-squared
map(model_list, get_mod_adj_r_squared) %>%
  as_tibble() %>%
  pivot_longer(model_A:model_C,
               names_to = "model",
               values_to = "adj_r_squared") %>%
  arrange(desc(adj_r_squared)) %>%
  knitr::kable()
```

Here is each model's cross-validation root mean squared error.
```{r}
# Perform cross validation for each model
map(model_list, get_cv_rmse) %>%
  as_tibble() %>%
  pivot_longer(model_A:model_C,
               names_to = "model",
               values_to = "RMSE") %>%
  arrange(RMSE) %>%
  ggplot(aes(x = model, y = RMSE, fill = model)) +
  geom_violin() + labs(x = "Model", y = "RMSE")
```

Further, we can plot the model residuals as a function of the model predictions.
```{r}
plot_model_residuals(model_A) +
plot_model_residuals(model_B) +
plot_model_residuals(model_C) +
plot_annotation(title = 'Model Residual as a function of Model Prediction',
                theme = theme(plot.title = element_text(size = 14)))
```


Q-Q plots

```{r}
par(mfrow = c(1,3))
plot_mod_qq(model_A)
plot_mod_qq(model_B)
plot_mod_qq(model_C)
```

Leverage plots
```{r}
par(mfrow = c(1,3))
plot_mod_leverage(model_A)
plot_mod_leverage(model_B)
plot_mod_leverage(model_C)
```

No wonder we had those weird distributions of RMSE in the Monte Carlo simulations - we had a serious outlier. Let's remove it and refit and re-validate the models.

```{r}
cdi_2 <- cdi %>% slice(-6)
# Get each model's adjusted r-squared
map(model_list, get_mod_adj_r_squared, data = cdi_2) %>%
  as_tibble() %>%
  pivot_longer(model_A:model_C,
               names_to = "model",
               values_to = "adj_r_squared") %>%
  arrange(desc(adj_r_squared)) %>%
  knitr::kable()

# Perform cross validation for each model
map(model_list, get_cv_rmse, data = cdi_2) %>%
  as_tibble() %>%
  pivot_longer(model_A:model_C,
               names_to = "model",
               values_to = "RMSE") %>%
  arrange(RMSE) %>%
  ggplot(aes(x = model, y = RMSE, fill = model)) +
  geom_violin() + labs(x = "Model", y = "RMSE")

#Residual plots
plot_model_residuals(model_A, data = cdi_2) + 
plot_model_residuals(model_B, data = cdi_2) +
plot_model_residuals(model_C, data = cdi_2) +
plot_annotation(title = 'Model Residual as a function of Model Prediction',
                theme = theme(plot.title = element_text(size = 14)))
  

#Q-Q plots
par(mfrow = c(1,3))
plot_mod_qq(model_A, data = cdi_2)
plot_mod_qq(model_B, data = cdi_2)
plot_mod_qq(model_C, data = cdi_2)

#Leverage plots
plot_mod_leverage(model_A, data = cdi_2)
plot_mod_leverage(model_B, data = cdi_2)
plot_mod_leverage(model_C, data = cdi_2)
```

For reasons listed in the paper, we will use model C. Let's summarize the
model.
```{r}
broom::tidy(lm(model_B, data = cdi_2)) %>%
  knitr::kable()
```

