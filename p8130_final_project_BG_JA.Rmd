---
title: "p8130_final_project_BG_JA"
author: "Benjamin Goebel, Jesse Ames"
date: "12/14/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(stringr)
```

Let's define helpful functions.
```{r}
# Functions

# Purpose: Calculates the Pearson's correlation coefficient between every
# variable in the data set and a specified variable.
# Arguments: v_name: a variable of type character that is the variable name
# Returns: A knitted table of correlations.
get_cor_by_var <- function(v_name) {
  cdi %>%
  map(~cor(as.numeric(.x), pull(cdi, v_name), method = "pearson")) %>%
  as_tibble() %>%
  pivot_longer(id:log_pop_density,
               names_to = "variables",
               values_to = "r") %>%
  mutate(
    sign = ifelse(r < 0, "-", "+"),
    r = abs(r)
  ) %>%
  arrange(desc(r)) %>%
  knitr::kable()
}

# Purpose: Fits the model and gets the model adjusted r-squared.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: A numeric, the model adjusted r-squared.
get_mod_adj_r_squared <- function(mod, data = cdi) {
  lm(mod, data = data) %>%
  broom::glance() %>%
  pull(adj.r.squared)
}

# Purpose: Performs cross validation on a model specified by its formula.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: A column vector of the model root mean squared errors generated by the validation procedure.
get_cv_rmse <- function(mod, data = cdi) {
  set.seed(1)
  crossv_mc(data, 1000) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  ) %>%
  mutate(
    fitted_mod = map(train, ~lm(mod, data = .x))
  ) %>%
  mutate(
    rmse_mod = map2_dbl(fitted_mod, test, ~rmse(model = .x, data = .y))
  ) %>%
  pull(rmse_mod)
}

# Purpose: Fits model.
#          Plots model residual as a function of model prediction for the given
#          model formula.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: The ggplot.
plot_model_residuals <- function(mod, data = cdi) {
  fitted_mod <- lm(mod, data = data) 
  cdi %>%
  add_predictions(fitted_mod) %>%
  add_residuals(fitted_mod) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  theme_bw() +
  labs(
    title = "Model Residual as a function of Model Prediction"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
}

# Purpose: Fits the specified model and creates a QQ Plot.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: The plot.
plot_mod_qq <- function(mod, data = cdi) {
  mod %>%
  lm(data = data) %>%
  plot(which = 2)
}


# Purpose: Fits the specified model and creates a leverage plot.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: The plot.
plot_mod_leverage <- function(mod, data = cdi) {
  mod %>%
  lm(data = data) %>%
  plot(which = 5)
}
```

Let's begin by reading in the data and adding a column for the crime rate
per 1,000 people in the county population. We will name this column `CRM_1000`.
We will then recode the region variable as a factor.
```{r message=FALSE}
cdi <- read_csv(here::here("data", "cdi.csv")) %>%
  mutate(CRM_1000 = (crimes/pop) * 1000,
         region = as.factor(region),
         region = fct_recode(region, "northeast" = "1", "north_central" = "2",
                             "south" = "3", "west" = "4"),
         pop_density = pop/area,
         log_pop18 = log(pop18),
         log_poverty = log(poverty),
         log_totalinc = log(totalinc),
         log_pcincome = log(pcincome),
         log_pop_density = log(pop_density))
```

Let's calculate the Pearson's correlation coefficient between every variable
in the data set and `CRM_1000`.

```{r warning=FALSE}
get_cor_by_var("CRM_1000")
```

Now, let's define models of interest.
```{r}
# Define model formulas and put in a list
model_A <- "CRM_1000 ~ region + log_pop_density + log_totalinc + log_pop18 + log_poverty"
model_B <- "CRM_1000 ~ region + log_pop_density + log_pcincome + log_poverty"
model_C <- "CRM_1000 ~ region + log_pop_density + log_totalinc + log_poverty"

model_list <-  
  list(
    model_A = model_A,
    model_B = model_B,
    model_C = model_C
  )
```

Here is each model's adjusted R-squared value.
```{r}
# Get each model's adjusted r-squared
map(model_list, get_mod_adj_r_squared) %>%
  as_tibble() %>%
  pivot_longer(model_A:model_C,
               names_to = "model",
               values_to = "adj_r_squared") %>%
  arrange(desc(adj_r_squared)) %>%
  knitr::kable()
```

Here is each model's cross-validation root mean squared error.
```{r}
# Perform cross validation for each model
map(model_list, get_cv_rmse) %>%
  as_tibble() %>%
  pivot_longer(model_A:model_C,
               names_to = "model",
               values_to = "RMSE") %>%
  arrange(RMSE) %>%
  ggplot(aes(x = model, y = RMSE, fill = model)) +
  geom_violin() + labs(x = "Model", y = "RMSE")
```

Further, we can plot the model residuals as a function of the model predictions.
```{r}
plot_model_residuals(model_A)
```

```{r}
plot_model_residuals(model_B)
```

```{r}
plot_model_residuals(model_C)
```


Q-Q plots
```{r}
plot_mod_qq(model_A)
```

```{r}
plot_mod_qq(model_B)
```

```{r}
plot_mod_qq(model_C)
```

Leverage plots
```{r}
plot_mod_leverage(model_A)
```

```{r}
plot_mod_leverage(model_B)
```

```{r}
plot_mod_leverage(model_C)
```

No wonder we had those weird distributions of RMSE in the Monte Carlo simulations - we had a serious outlier. Let's remove it and refit and re-validate the models.

```{r}
cdi_2 <- cdi %>% slice(-6)
# Get each model's adjusted r-squared
map(model_list, get_mod_adj_r_squared, data = cdi_2) %>%
  as_tibble() %>%
  pivot_longer(model_A:model_C,
               names_to = "model",
               values_to = "adj_r_squared") %>%
  arrange(desc(adj_r_squared)) %>%
  knitr::kable()

# Perform cross validation for each model
map(model_list, get_cv_rmse, data = cdi_2) %>%
  as_tibble() %>%
  pivot_longer(model_A:model_C,
               names_to = "model",
               values_to = "RMSE") %>%
  arrange(RMSE) %>%
  ggplot(aes(x = model, y = RMSE, fill = model)) +
  geom_violin() + labs(x = "Model", y = "RMSE")

#Residual plots
plot_model_residuals(model_A, data = cdi_2)
plot_model_residuals(model_B, data = cdi_2)
plot_model_residuals(model_C, data = cdi_2)

#Q-Q plots
plot_mod_qq(model_A, data = cdi_2)
plot_mod_qq(model_B, data = cdi_2)
plot_mod_qq(model_C, data = cdi_2)

#Leverage plots
plot_mod_leverage(model_A, data = cdi_2)
plot_mod_leverage(model_B, data = cdi_2)
plot_mod_leverage(model_C, data = cdi_2)
```

For reasons listed in the paper, we will use model C. Let's summarize the
model.
```{r}
broom::tidy(lm(model_C, data = cdi_2)) %>%
  knitr::kable()
```

