---
title: "p8130_final_project_BG_JA"
author: "Benjamin Goebel, Jesse Ames"
date: "12/14/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(stringr)
library(patchwork)
```

Let's define helpful functions.
```{r}
# Functions

# Purpose: Calculates the Pearson's correlation coefficient between every
# variable in the data set and a specified variable.
# Arguments: v_name: a variable of type character that is the variable name
# Returns: A knitted table of correlations.
get_cor_by_var <- function(v_name) {
  cdi %>%
  map(~cor(as.numeric(.x), pull(cdi, v_name), method = "pearson")) %>%
  as_tibble() %>%
  pivot_longer(CRM_1000:log_docbed,
               names_to = "variables",
               values_to = "r") %>%
  mutate(
    sign = ifelse(r < 0, "-", "+"),
    r = abs(r)
  ) %>%
  arrange(desc(r)) %>%
  knitr::kable()
}

# Purpose: Fits the model and gets the model adjusted r-squared.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: A numeric, the model adjusted r-squared.
get_mod_adj_r_squared <- function(mod, data = cdi) {
  lm(mod, data = data) %>%
  broom::glance() %>%
  pull(adj.r.squared)
}

# Purpose: Performs cross validation on a model specified by its formula.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: A column vector of the model root mean squared errors generated by the validation procedure.
get_cv_rmse <- function(mod, data = cdi) {
  set.seed(1)
  crossv_mc(data, 1000) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  ) %>%
  mutate(
    fitted_mod = map(train, ~lm(mod, data = .x))
  ) %>%
  mutate(
    rmse_mod = map2_dbl(fitted_mod, test, ~rmse(model = .x, data = .y))
  ) %>%
  pull(rmse_mod)
}

# Purpose: Fits model.
#          Plots model residual as a function of model prediction for the given
#          model formula.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: The ggplot.
plot_model_residuals <- function(mod, data = cdi) {
  fitted_mod <- lm(mod, data = data) 
  cdi %>%
  add_predictions(fitted_mod) %>%
  add_residuals(fitted_mod) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  theme_bw() +
  labs(
    title = "Model Residual as a function of Model Prediction"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
}

# Purpose: Fits the specified model and creates a QQ Plot.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: The plot.
plot_mod_qq <- function(mod, data = cdi) {
  mod %>%
  lm(data = data) %>%
  plot(which = 2)
}


# Purpose: Fits the specified model and creates a leverage plot.
# Arguments: mod: a variable of type character that is the formula to fit a 
#            linear model.
# Returns: The plot.
plot_mod_leverage <- function(mod, data = cdi) {
  mod %>%
  lm(data = data) %>%
  plot(which = 5)
}
```

Let's begin by reading in the data and adding a column for the crime rate
per 1,000 people in the county population. We will name this column `CRM_1000`.
We will then recode the region variable as a factor.
```{r message=FALSE}
cdi <- read_csv(here::here("data", "cdi.csv")) %>%
  mutate(CRM_1000 = (crimes/pop) * 1000,
         state = as.factor(state),
         region = as.factor(region),
         region = fct_recode(region, "northeast" = "1", "north_central" = "2",
                             "south" = "3", "west" = "4"),
         pop_density = pop/area,
         docbed = docs/beds,
         log_pop18 = log(pop18),
         log_pop65 = log(pop65),
         log_hsgrad = log(hsgrad),
         log_bagrad = log(bagrad),
         log_poverty = log(poverty),
         log_unemp = log(unemp),
         log_totalinc = log(totalinc),
         log_pcincome = log(pcincome),
         log_pop_density = log(pop_density),
         log_docbed = log(docbed)
         ) %>% 
  dplyr::select(-id, -cty, -docs, -beds, -crimes, -pop, -area) %>% 
  dplyr::select(CRM_1000, state, region, everything())
```

Let's calculate the Pearson's correlation coefficient between every variable
in the data set and `CRM_1000`.

```{r warning=FALSE}
get_cor_by_var("CRM_1000")
```


```{r}
cdi_long = 
  cdi %>% 
    pivot_longer(
      pop18:log_docbed,
      names_to = "var",
      values_to = "val"
    ) %>% 
  mutate(
    trans = case_when(grepl('log_', var) ~ 'log',
                     TRUE ~ 'ori'
    ),
    trans = factor(trans, levels = c("ori", "log"), labels =c("Untransformed", "log Transformed")),
    var = str_replace(var, "log_", ""),
    var = factor(var, levels = c("pop18", "pop65", "hsgrad", "bagrad", "poverty", "unemp", "pcincome", "totalinc", "pop_density", "docbed"))
  )

dens_plot_gen = function(v, b){
  
  if(!b){
    cdi_long %>% 
      filter(var == v) %>% 
      ggplot(aes(x = val)) +
      geom_boxplot() +
      theme_minimal() +
      theme(
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.text.x=element_blank()
      ) +
      facet_grid(var ~ trans, switch = "y", scales = "free") +
      theme(
        strip.text.y.left = element_text(angle = 0),
        strip.text.x = element_blank()
      )
  }else{
    cdi_long %>% 
      filter(var == v) %>% 
      ggplot(aes(x = val)) +
      geom_boxplot() +
      theme_minimal() +
      theme(
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.text.x=element_blank()
      ) +
      facet_grid(var ~ trans, switch = "y", scales = "free") +
      theme(
        strip.text.y.left = element_text(angle = 0)
      )
  }
}

var_list = c("pop18", "pop65", "hsgrad", "bagrad", "poverty", "unemp", "pcincome", "totalinc", "pop_density", "docbed")

plot_1 = dens_plot_gen(var_list[1], T)
plot_2 = dens_plot_gen(var_list[2], F)
plot_3 = dens_plot_gen(var_list[3], F)
plot_4 = dens_plot_gen(var_list[4], F)
plot_5 = dens_plot_gen(var_list[5], F)
plot_6 = dens_plot_gen(var_list[6], F)
plot_7 = dens_plot_gen(var_list[7], F)
plot_8 = dens_plot_gen(var_list[8], F)
plot_9 = dens_plot_gen(var_list[9], F)
plot_10 = dens_plot_gen(var_list[10], F)

patch_1 = plot_1 / plot_2 / plot_3 / plot_4 / plot_5 / plot_6 / plot_7 / plot_8 / plot_9 / plot_10

patch_1 + 
  plot_annotation(title = 'Untransformed and log Transformed Variable Distributions in the CDI Dataset',
                  theme = theme(plot.title = element_text(size = 14)))
```

Now, let's define models of interest.
```{r}
# Define model formulas and put in a list
model_A <- "CRM_1000 ~ region + log_pop_density + log_totalinc + log_pop18 + log_poverty"
model_B <- "CRM_1000 ~ region + log_pop_density + log_pcincome + log_poverty"
model_C <- "CRM_1000 ~ region + log_pop_density + log_totalinc + log_poverty"

model_list <-  
  list(
    model_A = model_A,
    model_B = model_B,
    model_C = model_C
  )
```

Here is each model's adjusted R-squared value.
```{r}
# Get each model's adjusted r-squared
map(model_list, get_mod_adj_r_squared) %>%
  as_tibble() %>%
  pivot_longer(model_A:model_C,
               names_to = "model",
               values_to = "adj_r_squared") %>%
  arrange(desc(adj_r_squared)) %>%
  knitr::kable()
```

Here is each model's cross-validation root mean squared error.
```{r}
# Perform cross validation for each model
map(model_list, get_cv_rmse) %>%
  as_tibble() %>%
  pivot_longer(model_A:model_C,
               names_to = "model",
               values_to = "RMSE") %>%
  arrange(RMSE) %>%
  ggplot(aes(x = model, y = RMSE, fill = model)) +
  geom_violin() + labs(x = "Model", y = "RMSE")
```

Further, we can plot the model residuals as a function of the model predictions.
```{r}
plot_model_residuals(model_A)
```

```{r}
plot_model_residuals(model_B)
```

```{r}
plot_model_residuals(model_C)
```


Q-Q plots
```{r}
plot_mod_qq(model_A)
```

```{r}
plot_mod_qq(model_B)
```

```{r}
plot_mod_qq(model_C)
```

Leverage plots
```{r}
plot_mod_leverage(model_A)
```

```{r}
plot_mod_leverage(model_B)
```

```{r}
plot_mod_leverage(model_C)
```

No wonder we had those weird distributions of RMSE in the Monte Carlo simulations - we had a serious outlier. Let's remove it and refit and re-validate the models.

```{r}
cdi_2 <- cdi %>% slice(-6)
# Get each model's adjusted r-squared
map(model_list, get_mod_adj_r_squared, data = cdi_2) %>%
  as_tibble() %>%
  pivot_longer(model_A:model_C,
               names_to = "model",
               values_to = "adj_r_squared") %>%
  arrange(desc(adj_r_squared)) %>%
  knitr::kable()

# Perform cross validation for each model
map(model_list, get_cv_rmse, data = cdi_2) %>%
  as_tibble() %>%
  pivot_longer(model_A:model_C,
               names_to = "model",
               values_to = "RMSE") %>%
  arrange(RMSE) %>%
  ggplot(aes(x = model, y = RMSE, fill = model)) +
  geom_violin() + labs(x = "Model", y = "RMSE")

#Residual plots
plot_model_residuals(model_A, data = cdi_2)
plot_model_residuals(model_B, data = cdi_2)
plot_model_residuals(model_C, data = cdi_2)

#Q-Q plots
plot_mod_qq(model_A, data = cdi_2)
plot_mod_qq(model_B, data = cdi_2)
plot_mod_qq(model_C, data = cdi_2)

#Leverage plots
plot_mod_leverage(model_A, data = cdi_2)
plot_mod_leverage(model_B, data = cdi_2)
plot_mod_leverage(model_C, data = cdi_2)
```

For reasons listed in the paper, we will use model C. Let's summarize the
model.
```{r}
broom::tidy(lm(model_C, data = cdi_2)) %>%
  knitr::kable()
```

